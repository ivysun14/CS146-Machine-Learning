{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H420KxmCjKH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCDUFCh7Fd-n",
        "outputId": "348eebe9-d4c2-4312-f066-75edfd2210bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# To add your own Drive Run this cell.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQXiXrbaF3NK"
      },
      "outputs": [],
      "source": [
        "# Please append your own directory after â€˜/content/drive/My Drive/'\n",
        "### ========== TODO : START ========== ###\n",
        "sys.path += ['/content/drive/My Drive/CS M146/HW3-code'] \n",
        "### ========== TODO : END ========== ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_OLupUPC2U3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Author      : Yi-Chieh Wu, Sriram Sankararman\n",
        "Description : Twitter\n",
        "\"\"\"\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# !!! MAKE SURE TO USE SVC.decision_function(X), NOT SVC.predict(X) !!!\n",
        "# (this makes ``continuous-valued'' predictions)\n",
        "from sklearn.svm import SVC\n",
        "#from sklearn.cross_validation import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "47L2XVzBX6c5"
      },
      "source": [
        "# Problem: Twitter Analysis Using SVM\n",
        "In this project, you will be working with Twitter data. Specifically, we have supplied you with a number of tweets that are reviews/reactions to movies, \n",
        "\n",
        "e.g., <i> \"@nickjfrost just saw The Boat That Rocked/Pirate Radio and I thought it was brilliant! You and the rest of the cast were fantastic! < 3\". </i>\n",
        "\n",
        "You will learn to automatically classify such tweets as either positive or negative reviews. To do this, you will employ Support Vector Machines (SVMs), a popular choice for a large number of classification problems.\n",
        "\n",
        "Datasets:\n",
        "* **tweets.txt** contains 630 tweets about movies. Each line in the file contains exactly one tweet, so there are 630 lines in total.\n",
        "\n",
        "* **labels.txt** contains the corresponding labels. If a tweet praises or recommends a movie, it is classified as a positive review and labeled +1; otherwise it is classified as a negative review and labeled -1. These labels are ordered, i.e. the label for the ith tweet in tweets.txt corresponds to the ith number in labels.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z8E5YL0CzWe"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# functions -- input/output\n",
        "######################################################################\n",
        "\n",
        "def read_vector_file(fname):\n",
        "    \"\"\"\n",
        "    Reads and returns a vector from a file.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        fname  -- string, filename\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        labels -- numpy array of shape (n,)\n",
        "                    n is the number of non-blank lines in the text file\n",
        "    \"\"\"\n",
        "    return np.genfromtxt(fname)\n",
        "\n",
        "\n",
        "def write_label_answer(vec, outfile):\n",
        "    \"\"\"\n",
        "    Writes your label vector to the given file.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        vec     -- numpy array of shape (n,) or (n,1), predicted scores\n",
        "        outfile -- string, output filename\n",
        "    \"\"\"\n",
        "\n",
        "    # for this project, you should predict 70 labels\n",
        "    if(vec.shape[0] != 70):\n",
        "        print(\"Error - output vector should have 70 rows.\")\n",
        "        print(\"Aborting write.\")\n",
        "        return\n",
        "\n",
        "    np.savetxt(outfile, vec)\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Feature Extraction\n",
        "\n",
        "Here we use a bag-of-words model to convert each tweet into a feature vector. A bag-of-words model treats a text file as a collection of words, disregarding word order. The first step in building a bag-of-words model involves building a \"dictionary\". A dictionary contains all of the unique words in the text file. \n",
        "\n",
        "For this project, punctuations were included in the dictionary as well. For example, a text file containing <i>\"John likes movies. Mary likes movies2!!\"</i> will have a dictionary $\\textbf{\\{'John':0, 'Mary':1, 'likes':2, 'movies':3, 'movies2':4, '.':5, '!':6\\}}$. \n",
        "\n",
        "The $\\textbf{(key,value)}$ pairs are $\\textbf{(word, index)}$, where the index keeps track of the number of unique words (size of the dictionary). Given a dictionary containing $d$ unique words, we can transform the $n$ variable-length tweets into $n$ feature vectors of length $d$ by setting the $i^{th}$ element of the $j^{th}$ feature vector to 1 if the $i^{th}$ dictionary word is in the $j^{th}$ tweet, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i67aTAmrGGHi"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# functions -- feature extraction\n",
        "######################################################################\n",
        "\n",
        "def extract_words(input_string):\n",
        "    \"\"\"\n",
        "    Processes the input_string, separating it into \"words\" based on the presence\n",
        "    of spaces, and separating punctuation marks into their own words.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        input_string -- string of characters\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        words        -- list of lowercase \"words\"\n",
        "    \"\"\"\n",
        "\n",
        "    for c in punctuation :\n",
        "        input_string = input_string.replace(c, ' ' + c + ' ')\n",
        "    return input_string.lower().split()\n",
        "\n",
        "\n",
        "def extract_dictionary(infile):\n",
        "    \"\"\"\n",
        "    Given a filename, reads the text file and builds a dictionary of unique\n",
        "    words/punctuations.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        infile    -- string, filename\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        word_list -- dictionary, (key, value) pairs are (word, index)\n",
        "    \"\"\"\n",
        "\n",
        "    word_list = {}\n",
        "    idx = 0\n",
        "    with open(infile, 'r') as fid :\n",
        "        ### ========== TODO : START ========== ###\n",
        "        # part 1a: process each line to populate word_list\n",
        "\n",
        "        for line in fid: # read tweet by tweet\n",
        "            tweet = extract_words(line) # list of \"words\"\n",
        "            for word in tweet:\n",
        "                if word not in word_list: \n",
        "                  word_list[word] = idx\n",
        "                  idx += 1\n",
        "\n",
        "        ### ========== TODO : END ========== ###\n",
        "\n",
        "    return word_list\n",
        "\n",
        "\n",
        "def extract_feature_vectors(infile, word_list):\n",
        "    \"\"\"\n",
        "    Produces a bag-of-words representation of a text file specified by the\n",
        "    filename infile based on the dictionary word_list.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        infile         -- string, filename\n",
        "        word_list      -- dictionary, (key, value) pairs are (word, index)\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        feature_matrix -- numpy array of shape (n,d)\n",
        "                          boolean (0,1) array indicating word presence in a string\n",
        "                            n is the number of non-blank lines in the text file\n",
        "                            d is the number of unique words in the text file\n",
        "    \"\"\"\n",
        "\n",
        "    num_lines = sum(1 for line in open(infile,'rU'))\n",
        "    num_words = len(word_list)\n",
        "    feature_matrix = np.zeros((num_lines, num_words))\n",
        "\n",
        "    with open(infile, 'r') as fid :\n",
        "        ### ========== TODO : START ========== ###\n",
        "        # part 1b: process each line to populate feature_matrix\n",
        "        line_num = 0\n",
        "\n",
        "        for line in fid:\n",
        "            tweet = extract_words(line)\n",
        "            for key, value in word_list.items():\n",
        "                if key in tweet: feature_matrix[line_num][value] = 1\n",
        "            line_num += 1\n",
        "        ### ========== TODO : END ========== ###\n",
        "\n",
        "    return feature_matrix"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Hyperparameter Selection for a Linear-Kernel SVM and an RBF-kernel SVM\n",
        "\n",
        "Next, we will learn a classifier to separate the training data into positive and negative tweets. For the classifier, we will use SVMs with two different kernels: linear and radial basis function (RBF). \n",
        "\n",
        "The **sklearn.svm.SVC** class was used and only three of the initialization parameters: **kernel**, **gamma**, and **C** were explicitly set. **SVC.fit(X,y)** was used to train the SVM, but in lieu of using **SVC.predict(X)** to make predictions, **SVC.decision_function(X)**, which returns the (signed) distance of the samples to the separating hyperplane, was used instead.\n",
        "\n",
        "SVMs have hyperparameters that must be set by the user. For both linear and RBF-kernel SVMs, hyperparameters were selected using 5-fold cross-validation (CV). Using 5-fold CV, we will select the hyperparameters that lead to the â€˜bestâ€™ mean performance across all 5 folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MvTxQPRGOOf"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# functions -- evaluation\n",
        "######################################################################\n",
        "\n",
        "def performance(y_true, y_pred, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Calculates the performance metric based on the agreement between the\n",
        "    true labels and the predicted labels.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        y_true -- numpy array of shape (n,), known labels\n",
        "        y_pred -- numpy array of shape (n,), (continuous-valued) predictions\n",
        "        metric -- string, option used to select the performance measure\n",
        "                  options: 'accuracy', 'f1_score', 'auroc', 'precision',\n",
        "                           'sensitivity', 'specificity'\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        score  -- float, performance score\n",
        "    \"\"\"\n",
        "    # map continuous-valued predictions to binary labels\n",
        "    y_label = np.sign(y_pred)\n",
        "    y_label[y_label==0] = 1\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 2a: compute classifier performance\n",
        "    if metric == \"accuracy\": \n",
        "      score = metrics.accuracy_score(y_true,y_label)\n",
        "    elif metric == \"f1_score\":\n",
        "      score = metrics.f1_score(y_true,y_label)\n",
        "    elif metric == \"auroc\":\n",
        "      score = metrics.roc_auc_score(y_true, y_label)\n",
        "    elif metric == \"precision\":\n",
        "      score = metrics.precision_score(y_true, y_label)\n",
        "    else:\n",
        "      mcm = metrics.confusion_matrix(y_true, y_label) # 2 by 2 this case\n",
        "      tn, fp, fn, tp = mcm.ravel()\n",
        "      if metric == \"sensitivity\": # true positive rate\n",
        "        score = tp / (tp + fn)\n",
        "      if metric == \"specificity\": # true negative rate\n",
        "        score = tn / (tn + fp)\n",
        "    ### ========== TODO : END ========== ###\n",
        "    return score\n",
        "\n",
        "def cv_performance(clf, X, y, kf, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Splits the data, X and y, into k-folds and runs k-fold cross-validation.\n",
        "    Trains classifier on k-1 folds and tests on the remaining fold.\n",
        "    Calculates the k-fold cross-validation performance metric for classifier\n",
        "    by averaging the performance across folds.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        clf    -- classifier (instance of SVC)\n",
        "        X      -- numpy array of shape (n,d), feature vectors\n",
        "                    n = number of examples\n",
        "                    d = number of features\n",
        "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
        "        kf     -- cross_validation.KFold or cross_validation.StratifiedKFold\n",
        "        metric -- string, option used to select performance measure\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        score   -- float, average cross-validation performance across k folds\n",
        "    \"\"\"\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 2b: compute average cross-validation performance\n",
        "    metric_score = np.zeros(kf.get_n_splits(X, y))\n",
        "    counter = 0\n",
        "    # split data based on cross validation kf\n",
        "    for train_index, test_index in kf.split(X,y): # loop for k times aka k folds\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        # train SVM\n",
        "        clf.fit(X_train, y_train)\n",
        "        # predict using trained classifier\n",
        "        y_pred = clf.decision_function(X_test)\n",
        "        # metric score\n",
        "        metric_score[counter] = performance(y_test, y_pred, metric)\n",
        "        counter += 1\n",
        "    \n",
        "    score = np.average(metric_score)\n",
        "\n",
        "    return score\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "def select_param_linear(X, y, kf, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Sweeps different settings for the hyperparameter of a linear-kernel SVM,\n",
        "    calculating the k-fold CV performance for each setting, then selecting the\n",
        "    hyperparameter that 'maximize' the average k-fold CV performance.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        X      -- numpy array of shape (n,d), feature vectors\n",
        "                    n = number of examples\n",
        "                    d = number of features\n",
        "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
        "        kf     -- cross_validation.KFold or cross_validation.StratifiedKFold\n",
        "        metric -- string, option used to select performance measure\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        C -- float, optimal parameter value for linear-kernel SVM\n",
        "    \"\"\"\n",
        "\n",
        "    print('Linear SVM Hyperparameter Selection based on ' + str(metric) + ':')\n",
        "    C_range = 10.0 ** np.arange(-3, 3)\n",
        "    \n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 2c: select optimal hyperparameter using cross-validation\n",
        "    c_score = np.zeros(len(C_range))\n",
        "    counter = 0\n",
        "    for c in C_range:\n",
        "      clf = SVC(kernel = 'linear', C=c) # define SVM instance\n",
        "      c_score[counter] = cv_performance(clf, X, y, kf, metric)\n",
        "      counter += 1\n",
        "\n",
        "    C = C_range[np.argmax(c_score)]\n",
        "    print(f\"For {metric}, cv scores across different parameters are {c_score}\")\n",
        "\n",
        "    return C\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "def select_param_rbf(X, y, kf, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Sweeps different settings for the hyperparameters of an RBF-kernel SVM,\n",
        "    calculating the k-fold CV performance for each setting, then selecting the\n",
        "    hyperparameters that 'maximize' the average k-fold CV performance.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        X       -- numpy array of shape (n,d), feature vectors\n",
        "                     n = number of examples\n",
        "                     d = number of features\n",
        "        y       -- numpy array of shape (n,), binary labels {1,-1}\n",
        "        kf     -- cross_validation.KFold or cross_validation.StratifiedKFold\n",
        "        metric  -- string, option used to select performance measure\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        gamma, C -- tuple of floats, optimal parameter values for an RBF-kernel SVM\n",
        "    \"\"\"\n",
        "\n",
        "    print('RBF SVM Hyperparameter Selection based on ' + str(metric) + ':')\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 3b: create grid, then select optimal hyperparameters using cross-validation\n",
        "    C_range = 10.0 ** np.arange(-3, 4)\n",
        "    gamma_range = 10.0 ** np.arange(-5, 2)\n",
        "\n",
        "    tuple_score = np.zeros(len(C_range)*len(gamma_range))\n",
        "    counter = 0\n",
        "\n",
        "    for c in C_range:\n",
        "      for gamma in gamma_range:\n",
        "        clf = SVC(kernel = 'rbf', C=c, gamma=gamma) # define SVM instance\n",
        "        tuple_score[counter] = cv_performance(clf, X, y, kf, metric)\n",
        "        counter += 1\n",
        "\n",
        "    index = np.argmax(tuple_score)\n",
        "    best_tuple = (gamma_range[index%7], C_range[index//7])\n",
        "    print(f\"For {metric}, the best cv scores across different parameters is {tuple_score[index]}\")\n",
        "\n",
        "    return best_tuple\n",
        "\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "def performance_test(clf, X, y, metric=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Estimates the performance of the classifier using the 95% CI.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        clf          -- classifier (instance of SVC)\n",
        "                          [already fit to data]\n",
        "        X            -- numpy array of shape (n,d), feature vectors of test set\n",
        "                          n = number of examples\n",
        "                          d = number of features\n",
        "        y            -- numpy array of shape (n,), binary labels {1,-1} of test set\n",
        "        metric       -- string, option used to select performance measure\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        score        -- float, classifier performance\n",
        "        lower, upper -- tuple of floats, confidence interval\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 4b: return the values of test results under a metric.\n",
        "    y_pred = clf.decision_function(X)\n",
        "    score = performance(y, y_pred, metric)\n",
        "    \n",
        "    return score\n",
        "    ### ========== TODO : END ========== ###"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Set Performance\n",
        "\n",
        "Apply the two classifiers learned in the previous sections to the test data and measure performance.\n",
        "\n",
        "Performance was measured using the following metrics: \n",
        "* accuracy\n",
        "* F1-Score\n",
        "* AUROC\n",
        "* precision\n",
        "* sensitivity\n",
        "* specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMIQRGpYErVF",
        "outputId": "d99602e8-8109-4b93-c861-95978a27ac4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: DeprecationWarning: 'U' mode is deprecated\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear SVM Hyperparameter Selection based on accuracy:\n",
            "For accuracy, cv scores across different parameters are [0.71019949 0.7119852  0.80701416 0.81586229 0.81406049 0.81406049]\n",
            "Linear SVM Hyperparameter Selection based on f1_score:\n",
            "For f1_score, cv scores across different parameters are [0.83053918 0.83140994 0.87553669 0.87589031 0.87427006 0.87427006]\n",
            "Linear SVM Hyperparameter Selection based on auroc:\n",
            "For auroc, cv scores across different parameters are [0.5        0.5030303  0.71801376 0.75219913 0.7509333  0.7509333 ]\n",
            "Linear SVM Hyperparameter Selection based on precision:\n",
            "For precision, cv scores across different parameters are [0.71019949 0.7114704  0.83460665 0.85568989 0.85530219 0.85530219]\n",
            "Linear SVM Hyperparameter Selection based on sensitivity:\n",
            "For sensitivity, cv scores across different parameters are [1.         1.         0.92939873 0.90420886 0.90167722 0.90167722]\n",
            "Linear SVM Hyperparameter Selection based on specificity:\n",
            "For specificity, cv scores across different parameters are [0.         0.00606061 0.50662879 0.60018939 0.60018939 0.60018939]\n",
            "Optimal C for each metric is [1.    1.    1.    1.    0.001 1.   ]\n",
            "RBF SVM Hyperparameter Selection based on accuracy:\n",
            "For accuracy, the best cv scores across different parameters is 0.8158462033462033\n",
            "RBF SVM Hyperparameter Selection based on f1_score:\n",
            "For f1_score, the best cv scores across different parameters is 0.8770973203699721\n",
            "RBF SVM Hyperparameter Selection based on auroc:\n",
            "For auroc, the best cv scores across different parameters is 0.7503241273494439\n",
            "RBF SVM Hyperparameter Selection based on precision:\n",
            "For precision, the best cv scores across different parameters is 0.8556226615431288\n",
            "RBF SVM Hyperparameter Selection based on sensitivity:\n",
            "For sensitivity, the best cv scores across different parameters is 1.0\n",
            "RBF SVM Hyperparameter Selection based on specificity:\n",
            "For specificity, the best cv scores across different parameters is 0.593939393939394\n",
            "Optimal gamma and C for each metric is [[1.e-03 1.e+03]\n",
            " [1.e-03 1.e+02]\n",
            " [1.e-03 1.e+03]\n",
            " [1.e-02 1.e+02]\n",
            " [1.e-05 1.e-03]\n",
            " [1.e-02 1.e+02]]\n",
            "[0.73913043 0.47058824 0.63839286 0.61538462 0.38095238 0.89583333]\n",
            "[0.75362319 0.48484848 0.64880952 0.66666667 0.38095238 0.91666667]\n"
          ]
        }
      ],
      "source": [
        "######################################################################\n",
        "# main\n",
        "######################################################################\n",
        "\n",
        "def main() :\n",
        "    np.random.seed(1234)\n",
        "\n",
        "    # read the tweets and its labels, change the following two lines to your own path.\n",
        "    file_path = '/content/drive/My Drive/CS M146/HW3-code/data/tweets.txt'\n",
        "    label_path = '/content/drive/My Drive/CS M146/HW3-code/data/labels.txt'\n",
        "    dictionary = extract_dictionary(file_path)\n",
        "    print(len(dictionary))\n",
        "    X = extract_feature_vectors(file_path, dictionary)\n",
        "    y = read_vector_file(label_path)\n",
        "\n",
        "\n",
        "    metric_list = [\"accuracy\", \"f1_score\", \"auroc\", \"precision\", \"sensitivity\", \"specificity\"]\n",
        "\n",
        "    ### ========== TODO : START ========== ###\n",
        "    # part 1c: split data into training (training + cross-validation) and testing set\n",
        "    X_training = X[0:559]\n",
        "    y_training = y[0:559]\n",
        "    X_test = X[560:629]\n",
        "    y_test = y[560:629]\n",
        "    # part 2b: create stratified folds (5-fold CV)\n",
        "    kf = StratifiedKFold(n_splits=5)\n",
        "    # part 2d: for each metric, select optimal hyperparameter for linear-kernel SVM using CV\n",
        "    optimalC_each_metric = np.zeros(len(metric_list))\n",
        "    for i in range(len(metric_list)):\n",
        "      C_optimal = select_param_linear(X_training, y_training, kf, metric=metric_list[i])\n",
        "      optimalC_each_metric[i] = C_optimal\n",
        "    print(f\"Optimal C for each metric is {optimalC_each_metric}\")\n",
        "    # part 3c: for each metric, select optimal hyperparameter for RBF-SVM using CV\n",
        "    optimalTuple_each_metric = np.zeros((len(metric_list), 2))\n",
        "    for i in range(len(metric_list)):\n",
        "      tuple_optimal = select_param_rbf(X_training, y_training, kf, metric=metric_list[i])\n",
        "      optimalTuple_each_metric[i] = tuple_optimal\n",
        "    print(f\"Optimal gamma and C for each metric is {optimalTuple_each_metric}\")\n",
        "    # part 4a: train linear- and RBF-kernel SVMs with selected hyperparameters\n",
        "    linear_clf = SVC(kernel = 'linear', C=1)\n",
        "    rbf_clf = SVC(kernel = 'rbf', C=1000, gamma=0.001)\n",
        "    \n",
        "    linear_clf = linear_clf.fit(X_training, y_training)\n",
        "    rbf_clf = rbf_clf.fit(X_training, y_training)\n",
        "    # part 4c: test the performance of your two classifiers.\n",
        "    linear_metric_score = np.zeros(len(metric_list))\n",
        "    rbf_metric_score = np.zeros(len(metric_list))\n",
        "\n",
        "    for i in range(len(metric_list)):\n",
        "      linear_metric_score[i] = performance_test(linear_clf, X_test, y_test, metric_list[i])\n",
        "      rbf_metric_score[i] = performance_test(rbf_clf, X_test, y_test, metric_list[i])\n",
        "\n",
        "    print(linear_metric_score)\n",
        "    print(rbf_metric_score)\n",
        "    ### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "    main()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_W-_mjX0JMes"
      },
      "source": [
        "# Problem: Boosting vs. Decision Tree\n",
        "\n",
        "In this exercise, we will compare Decision Tree (DT) to Random Forest, i.e., ensemble of different DTs on different features. \n",
        "\n",
        "We will explore the effect of two hyperparameters on ensemble performance: \n",
        "1. the number of samples in bootstrap sampling; \n",
        "2. the number of maximum features to use for each DT. \n",
        "\n",
        "Dataset: \n",
        "* **titanic_train.csv** contains demographic and ticket information for passengers and their survival status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uzCdPTkOQSY"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVxef2sxOmVI"
      },
      "outputs": [],
      "source": [
        "class Data :\n",
        "    \n",
        "    def __init__(self) :\n",
        "        \"\"\"\n",
        "        Data class.\n",
        "        \n",
        "        Attributes\n",
        "        --------------------\n",
        "            X -- numpy array of shape (n,d), features\n",
        "            y -- numpy array of shape (n,), targets\n",
        "        \"\"\"\n",
        "                \n",
        "        # n = number of examples, d = dimensionality\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        \n",
        "        self.Xnames = None\n",
        "        self.yname = None\n",
        "    \n",
        "    def load(self, filename, header=0, predict_col=-1) :\n",
        "        \"\"\"Load csv file into X array of features and y array of labels.\"\"\"\n",
        "        \n",
        "        # determine filename\n",
        "        f = filename\n",
        "        \n",
        "        # load data\n",
        "        with open(f, 'r') as fid :\n",
        "            data = np.loadtxt(fid, delimiter=\",\", skiprows=header)\n",
        "        \n",
        "        # separate features and labels\n",
        "        if predict_col is None :\n",
        "            self.X = data[:,:]\n",
        "            self.y = None\n",
        "        else :\n",
        "            if data.ndim > 1 :\n",
        "                self.X = np.delete(data, predict_col, axis=1)\n",
        "                self.y = data[:,predict_col]\n",
        "            else :\n",
        "                self.X = None\n",
        "                self.y = data[:]\n",
        "        \n",
        "        # load feature and label names\n",
        "        if header != 0:\n",
        "            with open(f, 'r') as fid :\n",
        "                header = fid.readline().rstrip().split(\",\")\n",
        "                \n",
        "            if predict_col is None :\n",
        "                self.Xnames = header[:]\n",
        "                self.yname = None\n",
        "            else :\n",
        "                if len(header) > 1 :\n",
        "                    self.Xnames = np.delete(header, predict_col)\n",
        "                    self.yname = header[predict_col]\n",
        "                else :\n",
        "                    self.Xnames = None\n",
        "                    self.yname = header[0]\n",
        "        else:\n",
        "            self.Xnames = None\n",
        "            self.yname = None\n",
        "\n",
        "\n",
        "# helper functions\n",
        "def load_data(filename, header=0, predict_col=-1) :\n",
        "    \"\"\"Load csv file into Data class.\"\"\"\n",
        "    data = Data()\n",
        "    data.load(filename, header=header, predict_col=predict_col)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zcf4WVqJSpe"
      },
      "outputs": [],
      "source": [
        "# Change the path to your own data directory\n",
        "titanic = load_data(\"/content/drive/My Drive/CS M146/HW3-code/data/titanic_train.csv\", header=1, predict_col=0)\n",
        "X = titanic.X; Xnames = titanic.Xnames\n",
        "y = titanic.y; yname = titanic.yname\n",
        "n,d = X.shape  # n = number of examples, d =  number of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ta7XHRWQGNo"
      },
      "outputs": [],
      "source": [
        "def error(clf, X, y, ntrials=100, test_size=0.2) :\n",
        "    \"\"\"\n",
        "    Computes the classifier error over a random split of the data,\n",
        "    averaged over ntrials runs.\n",
        "\n",
        "    Parameters\n",
        "    --------------------\n",
        "        clf         -- classifier\n",
        "        X           -- numpy array of shape (n,d), features values\n",
        "        y           -- numpy array of shape (n,), target classes\n",
        "        ntrials     -- integer, number of trials\n",
        "\n",
        "    Returns\n",
        "    --------------------\n",
        "        train_error -- float, training error\n",
        "        test_error  -- float, test error\n",
        "    \"\"\"\n",
        "\n",
        "    train_error = 0\n",
        "    test_error = 0\n",
        "\n",
        "    train_scores = []; test_scores = [];\n",
        "    for i in range(ntrials):\n",
        "        xtrain, xtest, ytrain, ytest = train_test_split (X,y, test_size = test_size, random_state = i)\n",
        "        clf.fit (xtrain, ytrain)\n",
        "\n",
        "        ypred = clf.predict (xtrain)\n",
        "        err = 1 - metrics.accuracy_score (ytrain, ypred, normalize = True)\n",
        "        train_scores.append (err)\n",
        "\n",
        "        ypred = clf.predict (xtest)\n",
        "        err = 1 - metrics.accuracy_score (ytest, ypred, normalize = True)\n",
        "        test_scores.append (err)\n",
        "\n",
        "    train_error =  np.mean (train_scores)\n",
        "    test_error = np.mean (test_scores)\n",
        "    return train_error, test_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8-U3un5PjGq",
        "outputId": "a0279567-c540-4951-8505-b66041c13416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifying using Decision Tree...\n",
            "\t-- training error: 0.014\n"
          ]
        }
      ],
      "source": [
        "### ========== TODO : START ========== ###\n",
        "# Part 5(a): Implement the decision tree classifier and report the training error.\n",
        "print('Classifying using Decision Tree...')\n",
        "model = DecisionTreeClassifier(criterion='entropy')\n",
        "clf = model.fit(X, y)\n",
        "y_pred = clf.predict(X)\n",
        "train_error = 1 - metrics.accuracy_score(y, y_pred, normalize=True)\n",
        "print('\\t-- training error: %.3f' % train_error)\n",
        "### ========== TODO : END ========== ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBYsOn49P_Ug",
        "outputId": "dbc9ddfe-513e-43ca-f962-b9f260bbbd0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDecision Tree\t-- avg train error : 0.012\tavg test error : 0.239\n"
          ]
        }
      ],
      "source": [
        "train_error, test_error = error (DecisionTreeClassifier (criterion = 'entropy'), X, y)\n",
        "print('\\tDecision Tree\\t-- avg train error : %.3f\\tavg test error : %.3f' %(train_error, test_error))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x_PevK8Q4dx",
        "outputId": "788fa723-6b4c-431d-ebe0-8b8e511682b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09295254833040423\n",
            "0.1885314685314685\n",
            "0.30000000000000004\n"
          ]
        }
      ],
      "source": [
        "### ========== TODO : START ========== ###\n",
        "# Part 5(b): Implement the random forest classifier and adjust the number of samples used in bootstrap sampling.\n",
        "max_sample = np.arange(0.1, 0.9, 0.1)\n",
        "train_error_vec = np.zeros(len(max_sample))\n",
        "test_error_vec = np.zeros(len(max_sample))\n",
        "\n",
        "for i in range(len(max_sample)):\n",
        "  model = RandomForestClassifier(criterion=\"entropy\", max_samples=max_sample[i])\n",
        "  train_error, test_error = error(model, X, y)\n",
        "  train_error_vec[i] = train_error\n",
        "  test_error_vec[i] = test_error\n",
        "\n",
        "index = np.argmin(test_error_vec)\n",
        "best_train_error = train_error_vec[index]\n",
        "best_test_error = test_error_vec[index]\n",
        "best_max_sample = max_sample[index]\n",
        "\n",
        "print(best_train_error)\n",
        "print(best_test_error)\n",
        "print(best_max_sample)\n",
        "### ========== TODO : END ========== ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFUyPTPwT53v",
        "outputId": "9be1ee8c-e1e1-470c-edb3-fcc292693536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09298769771528997\n",
            "0.18587412587412586\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "### ========== TODO : START ========== ###\n",
        "# Part 5(c): Implement the random forest classifier and adjust the number of features for each decision tree.\n",
        "max_feature = np.arange(1, 8, 1)\n",
        "train_error_vec = np.zeros(len(max_feature))\n",
        "test_error_vec = np.zeros(len(max_feature))\n",
        "\n",
        "for i in range(len(max_feature)):\n",
        "  model = RandomForestClassifier(criterion=\"entropy\", max_features=max_feature[i] ,max_samples=0.3)\n",
        "  train_error, test_error = error(model, X, y)\n",
        "  train_error_vec[i] = train_error\n",
        "  test_error_vec[i] = test_error\n",
        "\n",
        "index = np.argmin(test_error_vec)\n",
        "best_train_error = train_error_vec[index]\n",
        "best_test_error = test_error_vec[index]\n",
        "best_max_feature = max_feature[index]\n",
        "\n",
        "print(best_train_error)\n",
        "print(best_test_error)\n",
        "print(best_max_feature)\n",
        "### ========== TODO : END ========== ###"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
